\RequirePackage{amsmath}
%\RequirePackage[l2tabu, orthodox]{nag}
\documentclass[french, english]{llncs}
\input{preamble/packages}
\input{preamble/math_basics}
\input{preamble/math_mine}
\input{preamble/redac}
\input{preamble/draw}
\input{preamble/acronyms}
\newcommand{\dollars}[1]{\SI{#1}[\$]{}}
\newcommand{\simplebet}[3]{(\dollars{#1}, #2; \dollars{#3})}

\begin{document}
%Reasons and means for modeling preferences as incomplete.
	\title{Preference models that relax completeness: why, how?}
	\author{Olivier Cailloux\inst{1} \and Sébastien Destercke\inst{2}}
	\institute{
		LAMSADE\\
		\email{olivier.cailloux@dauphine.fr}
		\and HDS
	}
	\hypersetup{
		pdfsubject={preference modeling},
		pdfkeywords={keyw1, keyw2}
	}
	\maketitle
	
	\abstract{Literature involving preferences of artificial agents or human beings often assume their preferences can be represented using a complete transitive binary relation. Much has been written however on more complex, or more interesting, models of preferences. In this article we review some of the reasons that have been put forward to justify more complex modeling, and review some of the techniques that have been proposed to obtain models of such preferences.}
	
	%Oddly enough, llncs class seems to set the indent to zero when typesetting the abstract.
	\setlength{\parindent}{1.5em}
	
	\section{Introduction}\label{sec:intro}
	Preferences of agents are usually assumed to be linear, that is complete, transitive and antisymmetric, or representable with a weak order (a complete and transitive binary relation). In practice, such assumptions limit the scope of preference models one can consider as legitimate, and are also falsified by observed empirical evidences. While models relaxing antisymmetry to allow indifference (relaxing antisymmetry) between options have been around for some time, models relaxing the assumptions of completeness or transitivity are more recent.
	
	There are two canonical fields where the modelling of preferences is a central topic: choosing an alternative when it is evaluated according to different aspects (a.k.a. multi-criteria decision making, or MCDM), and picking an alternative whose quality depends on states of the world that are uncertainly known. Although the two frameworks are formally similar to some extent, they also present some conceptual key differences. 
	
	In MCDM, the common assumption is that the alternatives, i.e., the state of the world is known without ambiguity, and the difficulty is to determine what are the user preferences over these different, but well-defined states. In decision making under uncertainty (DMU), the preferences of the user are usually assumed to be well-known, or at least to have been previously assessed in the form of utility functions, and the problem is to recommend an alternative given our uncertainty about the world. 
	
	In this paper, we will review some reasons to relax preference completeness and models (either in MCDM or DMU) that do so. Although this review will not be comprehensive, it will provide a sufficient number of pointers for the reader to get an overall idea. Given the space limitations, we will also not deal in details with the issue of transitivity. We will first review MCDM and DMU settings considering completeness in Section~\ref{sec:review}, before detailing how completeness can be perceived in descriptive and normative approaches (recalling their difference at the same time) in Section~\ref{sec:nordesc}. Finally, we review models that departs from completeness in Section~\ref{sec:incomp}.
	

	
	\section{Completeness in classical and less classical settings}\label{sec:review}
	In this section, we are going to recall the main models that consider completeness and transitivity of preferences as a consequence of natural requirements, if not as pre-requisite of any preference modelling. We will also recall normative views and descriptive views of these concepts. 
	
	\subsection{MCDM}
	In MCDM, the classical approach is to assume that the alternatives are evaluated using a set of criteria $\crits$, each having an evaluation scale $X_g$. The set of all possible alternatives is $\allalts = \prod_{g \in G} X_g$, that is, every combination of evaluations are considered possible. 
	We are interested in a preference relation $\succeq$ defined as a binary relation over $\allalts$.
	
	\begin{example}
		Say the \ac{DM} must choose what to plant in her garden. The set of alternatives $\allalts$ are all possible vegetables, the criteria $\crits = \{g_1, g_2, g_3\}$ measure the taste, quantity, and price of each vegetable, and $\alts \subseteq \allalts$ are the vegetables that are available this year for planting. $X_{g_1} = \{A, B, C, D\}$, a set of labels, with $x_1$ representing the taste of the vegetable $x \in \allalts$ as considered by the \ac{DM} ($A$ is the worst taste, $D$ the best), $X_{g_2} = [0, 100]$, with $x_2$ representing the number of meals that the \ac{DM} would enjoy if deciding to plant $x$, and $X_{g_3} = \R$, where $x_3$ indicates the price to pay for planting $x$.
	\end{example}
	
	Typical approaches in MCDM assume that there is some real-valued function $v: \allalts \to \R$ mapping alternatives to their values, and that $x \succeq y$ iff  $v(x) ≥ v(y)$.
	
	\subsection{DMU}
	In the simplest form of DMU considered here (SDMR, for Simple Decision Making under Risk), we consider a set $S$ of possible states of the world, a finite set of consequences $C$, and each act $x: S \to C$ is modeled as a function where $x(s)$ is the consequence of performing $x$ when $s$ is the actual state of the world. Define $\allalts$ in this case as the set of possible acts (thus $\allalts = C^S$).
	In SDMR, uncertainty is modeled by a probability measure $p$ over the power set of $S$, $\powerset{S}$, thus with $p(s) \in [0, 1]$ indicating the probability of occurence of $s$ (with $s \subseteq S$), and $p(S) = 1$. 
	We consider a preference relation $\succeq$ defined as a binary relation over $\allalts$.
	Given an act $x$ and a probability measure $p$, it is usually convenient to view $x$ as $p_x$, a probability mass over the consequences: define $p_x: C → [0, 1]$ as $p_x(c) = p(x^{-1}(c))$, where $x^{-1}(c)$ designate the set of states in which $x$ leads to the consequence $c$. Such a $p_x$ is usually called a lottery. In most numerical DMU frameworks, a utility function $u_1: C → \R$ mapping consequences to numbers is assumed (or derived), from which is then induced the classical expected utility criterion $u: \allalts → \R$ that represents the global utility of an act and that reads $u(x) = \sum_{s \in S} p(s) u_1(x(s))$. An act $x$ is then preferred to $y$ ($x \succeq y$) iff $u(x) ≥ u(y)$. 
	
	%It follows from this definition that $u$ and $u_1$ are coherent, in the following sense: given an act $x$ that brings a consequence $c$ with probability one, $u(x) = u_1(c)$.
	
	\begin{example}\label{exm:DMU}
		Assume you want to go out and wonder about the weather state ($S=\{A,B,C,D\}$), going from $A=$``shiny" to $D=$``stormy". Given this state, two actions are $x_1$: ``leave the umbrella home" and $x_2$: ``take the umbrella", and the consequences are $c_1$: ``unhappy", $c_2$: ``neither happy nor unhappy" and $c_3$: ``happy". If the weather is nice ($x_1(A)=c_3,x_2(A)=c_1$), not having an umbrella is enjoyable,  and having to bear one for nothing will make you unhappy. On the contrary, if it is stormy ($x_1(D)=c_1,x_2(D)=c_3$), you will be happy to have taken your umbrella, but quite unhappy if you end up wet. In the other situations, you are quite indifferent to both actions. Assuming that $p(A)=0.2, p(D)=0.6$, $p(B)=p(C)=0.1$, and that $u_1(c_i)=i-2$, we then have
		$$u(x_1)=0.2 \cdot 1 + 0.6 \cdot -1 <  u(x_2)=0.2 \cdot -1 + 0.6 \cdot 1$$
	\end{example}
	
	Expected utility has been justified axiomatically by different authors, the main ones being Savage~\cite{savage_foundations_1972}, De Finetti~\cite{definetti_probability_2017} and Von Neumann Morgenstern~\cite{von_neumann_theory_2004}. It is worth noticing that these settings are quite different.
	\begin{itemize}
		\item In De Finetti setting, utilities are given as random variables, and a precise price can be associated to each random variable. That reasoning should be probabilistic and choices made according to expected utility follow from two axioms: linearity and boundedness of those prices.
		\item von Neumann and Morgenstern postulate conditions on $\succeq$ ensuring that utility functions $u$ and $u_1$ satisfying the above conditions exist. The axioms assume completeness of the preferences, and the probabilities are assumed to be given.
		\item In Savage setting, both probabilities and expected utility follow from axioms about preferences between acts. In particular, the first axiom (P1) is that any pair of act should be comparable. Completeness is therefore postulated in the axioms, and expected utility and probabilistic reasoning follow from it. 
	\end{itemize}
	While these theoretical constructs have set very strong foundations for the use of probabilities, in practice experiments such as the Ellsberg urn (contradicting Savage sure-thing principle) suggest that people do not always act according to expected utility. 
	
	Since then, many different extensions have been proposed, some modifying the utilities~\cite{wakker_prospect_2010} or the probabilities~\cite{quiggin_generalized_2012}. Others simply propose to relax the probabilistic assumption, for instance by considering a possibilistic setting  (see~\cite{dubois_qualitative_2003}, that discusses Savage-like axioms), by considering sets of probabilities such as in decision under ambiguity~\cite{gajdos_attitude_2008}, or by simply considering completely missing information, such as Wald's~\cite{wald_statistical_1992} celebrated maximin criterion. 
	
	Such extensions address some of the observed behaviours deviating from expected utility, but keep assuming that all acts are comparable, i.e., that preferences are complete. Yet, if one considers that probabilities or utilities may be incompletely known, the next step is to consider that preferences as well could be.
	
	All models presented or advocated thus far assume that it is possible to order alternatives according to their value, as given by a real function. Thus, they require $\succeq$ to be complete and transitive (by which we mean that if $\succeq$ is incomplete or not transitive, then no suitable function exists).
	
	The two contexts we have introduced, multiple criteria and risk, use as a basis the notion of a preference relation. We need to say a word about what those preferences really represent and what the goal of modeling those may be. This is required to give meaning to discussion about which conditions are reasonable to postulate about $\succeq$, and how to check whether they hold.
	
	\section{Completeness in descriptive and normative approaches}
	
	
	
	\subsection{Descriptive approach}
	In the descriptive approach to preferences, the goal of the model is to reflect the observed behavior of a \ac{DM}. Typically, a set of sample choices of the \ac{DM} is first collected, say, of choices of food products in his favorite store, and we would then try to obtain the model that best reflects his choice attitude. Or, we would query an individual’s preference about pairs of objects, and then try to build a predictive model on the whole set of possible pairs of alternatives (a method called active learning in the machine learning community). Such a model may be used to predict his behavior, e.g. for marketing or regulation purposes. In those cases where its purpose is to replace the \ac{DM} by automatic choices, it is debatable whether the normative approach would not be better suited.
	
	Here is what von Neumann and Morgenstern say about the preference relation.
	
	“It is clear that every measurement --- or rather every claim of measurability --- must ultimately be based on some immediate sensation\ldots
	%, which possibly cannot and certainly need not be analyzed any futher.
	%[Such as the sensations of light, heat, muscular effort, etc., in the corresponding branches of physics.] 
	In the case of utility the immediate sensation of preference\ldots%--- of one object or aggregate of objects as against another --- 
	provides this basis\ldots %(3.1.2) (The square brackets indicate a footnote.)
	Let us for the moment accept the picture of an individual whose system of preferences is all-embracing and complete\ldots%, i.e. who, for any two objects or rather for any two imagined events, possesses a clear intuition of preference. More precisely
	 we expect him, for any two alternative events which are put before him as possibilities, to be able to tell which of the two he prefers.” %(3.3.2) (The “events” here correspond to what we call alternatives.)
	
	As the preference relation is considered basic under a purely descriptive approach, the preference itself should be easily observable, and uncontroversial. This permits to empirically test conditions postulated on $\succeq$. Either by asking the individual what she prefers (in which case we “observe” her answer), or by presenting a choice set and observing what she picks from that set (in real life or in a laboratory experiment). In the first case, we have however to be clear about what is meant by “prefers”, which is a reason why many experimenters prefer to go for the latter strategy.
	
	\subsection{Normative approach}
	Under the normative approach, the goal is to model on how the \ac{DM} ought to choose rationally. Rationality may corresponds to accepted external norms (axioms), or to rules accepted by the \ac{DM} after careful thinking. Hence, the decision outcome using such approach may differ from empirically observed decisions. Consider as an example a recruiter in an enterprise who wants to model the recruitment procedure. After having collected data, it may appear that for some (possibly unconscious) reason, the recruitment is biased against some particular socio-economic category. The \ac{DM} may then want to find a recruitment strategy that avoids such biases, therefore actively trying to build a model contradicting empirical observations. 
	
	%It may be, further, that the \ac{DM} himself is not happy about this situation. Thus, he may try to find a strategy of selecting employees that would avoid such biases, therefore actively trying \emph{not} to build a perfectly descriptive model of the normal selection attitude.
	
	When the focus is on providing decision help to a \ac{DM} by letting him think about the norms he prefers, rather than considering them as external rationality norms, %that he ought to follow under threat of being considered irrational, 
	the approach is often termed prescriptive, or constructive. Carefully and formally defining such terms is important, especially as different authors use them somewhat differently \citep{roy_decision_1993, tsoukias_concept_2007}. As we do not want to focus on such issues, we will use the term normative as an umbrella.

 \commentSD{Raccourcir/enlever des citations?}
 \citet{mcclennen_rationality_1990, guala_logic_2000} discuss philosophical grounds for accepting a normative model. \citet{anand_are_1987, mandler_difficult_2001} discuss normative grounds for usual axioms about preferences, including completeness.
	
	What is the best approach to adopt is not always obvious. For instance recommender systems often adopt a descriptive approach, mimicking choice behaviour to increase profit, for example. Yet, such an approach reflect our cognitive limitations, and it is not clear that a more thoughtful or normative-oriented (at least partially) process would not lead to more satisfying, diverse or surprising recommendations that may moreover be explainable.
	
	%When building recommender systems in the literature in artificial intelligence, the focus is often on descriptive approaches. This is usually left implicit, with no discussion about possible alternatives. We think however that an interesting path is offered by normative approaches. Descriptive approaches will, by design, reflect cognitive limitations exhibited by us, normal human beings. Those limitations are numerous and sometimes obviously not in agreement with what a more thoughtful and knowledgeable person would do, as is well known and will be illustrated in this article (although there is debate about how such a sentence is to be interpreted exactly, more about this later). Providing (more) normative-based automatic recommendations might help provide sound advices, help increase serendipity, and possibly reduce incitations to merchants to exploit imperfections on the human reasoning abilities by using marketing techniques that may lead to choices that the \ac{DM} himself would possibly reject when thinking more carefully. (As an old but known example, “the credit card lobby is said to insist that any price difference between cash and card purchases should be labeled a cash discount rather than a credit surcharge.” \citep{tversky_rational_1986}.) 
	
	\commentSD{La phrase suivante me parait un peu mal s'agencer avec le reste?}
	\citet{fischhoff_knowing_1980} \citep[also]{fischhoff_knowing_1988} discuss possible attitudes of an analyst wanting to take into account incompleteness of preferences.
	

	\section{Dropping completeness}\label{sec:incomp}
	
	
	\subsection{Defining and testing incompleteness}
	\label{sec:empirical}
	A precise definition of what the preference relation $\succeq$ represents is required for discussing conditions postulated about it. For “preference”, in its everyday usage, is very ambiguous. (\citet{frankfurt_freedom_1971} cites seven reasonable interpretations of the phrase “to want to”; this exercice transposes, \emph{mutatis mutandis}, to the concept of preference.)
	
	Expanding on the proposition of nVM, we define that the \ac{DM} \emph{prefers} $a$ to $b$ when he expresses an intuitive attraction towards $a$ when presented with $a$ and $b$, or an equal attraction towards $a$ and $b$; and this attraction is stable over time (at least within a short time span) and does not change with irrelevant changes in the context. The second part of our definition makes it applicable also in case the intuitive attraction felt by the \ac{DM} changes for no apparent reason, or depends on the context at the moment of presenting $a$ and $b$ to the \ac{DM}, for example whether it is currently raining. Here we are interested in the multicriteria and SDMR settings, thus we assume that $a, b$ are alternatives in $\allalts$ described by their evaluations on the criteria (in the first case) or by the relevant probability distributions and consequences (in the second case), and consider irrelevant changes in the context as anything that does not change those descriptions. 
	This is by no means the only reasonable definition of a preference relation. We discuss alternative definitions of the preference relation later.
	
	Under this definition, postulating completeness of $\succeq$ amounts to state that the intuitive attractions of the \ac{DM} towards alternatives do not vary within short time spans and do not depend on irrelevant changes in the context. We think this is one reasonable way of capturing the essence of completeness, and it makes the condition empirically testable.
	
	It appears that this completeness assumption is too strong, for lack of stability of preference over time for some pairs of alternatives. This is well known in the field of experimental psychology, and is not even presented as a remarkable fact. As \citet{tversky_intransitivity_1969} writes, individuals “are not perfectly consistent in their choices. When faced with repeated choices between x and y, people often choose x in some instances and y in others. Furthermore, such inconsistencies are observed even in the absence of systematic changes in the decision maker’s taste which might be due to learning or sequential effects. It seems, therefore, that the observed inconsistencies reflect inherent variability or momentary fluctuation in the evaluative process.” 
	
	This argument may not be strong enough however. In absence of other arguments, one might agree that preferences are in reality incomplete but claim that they may appropriately be \emph{modeled} as complete: a model of complete preferences would simply deviate from time to time from what individuals declare because of (perhaps rare) random fluctuations in their expressions of preferences. 
	In order to discuss this hypothesis, we turn to the second (and much more interesting) reason for failure of completeness, which is also brought by the literature in empirical psychology. It appears that preferences change may not be attributed solely to random fluctuations: they change in systematic ways according to changes in the presentation of the alternatives or the context that should have no impact from a normative point of view.
	
	Before turning to this aspect, let us note that \citet[p. 630]{von_neumann_theory_1953} \citep[also]{von_neumann_theory_2004} themselves considered completeness as a strong condition, as the following often cited quote indicates: “it is very dubious, whether the idealization of reality which treats this postulate as a valid one, is appropriate or even convenient”.

	\subsection{Empirical evidence of incompleteness}
	
	\commentSD{Peut-être réduire les ref quand il y en a plusieurs sur le même sujet? Je ne sais pas si c'est faisable. }
	In multicriteria contexts, psychologists have shown systematic differences between the so-called choice and matching elicitation procedures \citep{tversky_contingent_1988}. Assume you want to know which of two alternatives $x, y$ the \ac{DM} prefers, in a problem involving two criteria. You can present both and directly ask for a choice. Alternatively, the matching procedure consists in presenting alternative $x$ with its two evaluations $g_1(x), g_2(x)$, and present alternative $y'$ with only one evaluation $g_1(y') = g_1(y)$, and ask the \ac{DM} to state the value $g_2(y')$ which would make $y'$ indifferent to $x$. Assuming $\succeq$ satisfies dominance and transitivity, you then know that $x \succeq y$ iff $g_2(y') ≥ g_2(y)$. The authors investigate and confirm the prominence hypothesis, according to which the more prominent criterion has more importance in choice than in matching. We illustrate with one of their studies. The subject faces a hypothetical choice between two programs for control of a polluted beach. Program $x$ completely cleans up the beach at a yearly cost of \dollars{750 000}; program $y$ partially cleans it up for a yearly cost of \dollars{250 000}. They assume that pollution is the more prominent criterion here, hence expect that $x$ will be chosen more often in choice than in matching. Indeed, 48\% out of the 104 subjects confronted with a choice procedure selected $x$, whereas only 12\% out of the 170 subjects confronted with a matching procedure indirectly opted for $x$.
	
%	\citet{maccrimmon_real_1980} have collected preferences of individuals over alternatives in a risk setting, representing monetary bets. Their subjects are business executives. One of the most striking result of the study is that individuals order some pairs of alternatives differently depending on which other alternatives they are presented with. The study is run as follows. Each subject is presented instructions and three sets of five alternatives. (The same three sets of five alternatives are presented to every individual.) The subjects are asked to rank each alternative by order of preference. Each alternative has exactly two possible consequences (monetary outcomes), and can thus be fully described using three numbers: best outcome, probability of winning the best outcome, and worst outcome. We focus on two of these sets of five alternatives, labelled set B and C in the paper. Set B contains the alternatives $\simplebet{5}{1}{5}$, $\simplebet{20}{0.692}{3.90}$, $\simplebet{20}{0.2752}{-0.70}$, $\simplebet{20}{0.6185}{-19.30}$, $\simplebet{20}{0.9046}{-137.00}$. Set C contains $\simplebet{5}{1}{5}$, $\simplebet{10}{0.6185}{-3.10}$, $\simplebet{15}{0.6185}{-11.20}$, $\simplebet{20}{0.6185}{-19.30}$, $\simplebet{25}{0.6185}{-27.40}$. Observe that those sets contain the same first and fourth alternatives. However, 9 out of 40 subjects give those pairs of alternatives different relative positions depending on which set they are ranking (4 of them rank B1 above B4 but C4 above C1, and vice-versa for the other 5). This effect might be thought to be due to the individuals not taking the task seriously, or be attributed to random fluctuations. But as the authors note, this appears implausible because of the very regular choice patterns observed in the rest of the analysis.
	
	Similarly, in context of DMR, preferences between loteries may be elicited using questions about probability equivalent loteries, or about certainty equivalents. Systematic differences appear in the preferences exhibited between each mode of questioning \citep{luce_utility_2000}.
	
	The previous two studies illustrate a phenomenon known as preference reversal due to a breach of procedure invariance. Let us use a study of \citet{tversky_framing_1981} to show that preference reversal can also result from a breach of description invariance (also called a framing effect): expressed preferences can change by merely changing the description of the decision situation. The subjects, split in two groups, have to choose a preferred program to prepare against an epidemic outspring which will, if no action is taken, result in the death of 600 persons. The first group must choose between program $x$, which saves 200 persons, and program $y$, which saves 600 persons with 1 chance on 3, and otherwise saves nobody. Most persons in that group choose program $x$. The second group must choose between program $x'$, which lets 400 persons die, and $y'$, which results in nobody dying with 1 chance on 3, and otherwise the death of 600 persons. Most persons in the second group choose program $y'$. Observe that both choices are identical up to phrasing. Indeed, it is well-known in psychology that choices phrased as losses are evaluated differently than choices phrased as gains \citet{thaler_toward_1980}.
	
	Very numerous other studies in the multicriteria and risk case exist that show and discuss preference reversal effects \citep[Ch. 2]{deparis_etude_2012}, \citep{lichtenstein_construction_2006, tversky_framing_1981, tversky_causes_1990, kahneman_judgement_1981, kahneman_choices_2000}. How to best account for and predict preference reversals is still debated in the literature about experimental psychology, but it is consensual that these effects exist and can be predicted to a good extent \citep{wakker_prospect_2010, birnbaum_empirical_2017}. For example, skeptic researchers tried to show that preference reversals could be attributed to deficiencies in the design of the studies or lack of realism, but they finally admitted that the phenomenon is robust \citet{slovic_preference_1983}.
		
	This shows that the $\succeq$ relation is in general not complete, under the definition suggested above. Individuals do not have a clear, intuitive preference for each pairs of alternatives, but rather, at least for some of them, can be lead to declare preference for one, depending on how the problem has been presented. When thinking more about the comparison and presented with different views of the same problem, individuals may in some cases change their preference. This has been studied empirically \citep{slovic_who_1974, maccrimmon_utility_1979, lichtenstein_reversals_2006}, and \citet[pp. 101 – 103]{savage_foundations_1972} famously reported that it happened to him. 

\commentSD{Les paragraphe suivants me semblent largement réductible, si pas complètement oblitérable.}
One way wish however to model a preference relation as complete anyway, in order, for example, to benefit from increased simplicity, tractability, or mathematical elegance of such models. One path for doing this is to consider the context as fixed, for example, consider the way of presenting the alternatives to the \ac{DM} as fixed. Thus, for example, the model would represent the preference as stated by the \ac{DM} when asked questions in terms of choices, and not when he is interrogated in terms of matching. Furthermore, the model would represent not a preference understood as the expression of clear intuitive attraction from the \ac{DM} towards some alternative, but rather as the a noisy intuitive attraction, known only imperfectly by the \ac{DM}. 
	In some cases, this is a perfectly reasonable path to follow. This strategy is commonly followed in experimental psychology, for example, \citet{luce_utility_2000} indicates that his book is about studying preferences in terms of choice and not of judgment; \citet{maccrimmon_real_1980} indicates that some kind of loteries should not be considered to belong to the scope of the model. We of course do not claim that models of preference relations that assume completeness have no validity whatsoever, as the validity of a model depends on its purposes. 

In the case however not of psychologists but of researchers building recommender systems, it is unclear that this path should be systematically followed. Indeed, in some cases we may want the recommendations of the recommender system to be invariant to the particular details about how alternatives have been presented to the individual. Not only because we may not know how the alternatives have been presented (what the context is), but more fundamentally, because the individual may find the advices of a recommender system more sound if it is independent of minute details of the context. (Adopting this view of course makes the system closer to the normative approach.)
	
	These effects of preference reversals are of course not everywhere \citep[p. xvi]{lichtenstein_construction_2006}. You can’t make someone choose whatever you want just by presenting it in the right way. (Or, at least, and luckily, we do not yet know how to do that.) Thus, another way of viewing the experimental highlights discussed here above is that a more meaningful model may be built on some subset of pairs that exhibit a stable preference. By forcing completeness in the model, we may build models that are partly irrelevant to the perception of the \ac{DM} we try to help: for some pairs of alternatives, there may be no sensible way, even conceptually, to determine which alternative is really preferred by the \ac{DM}.
	
	Talk here about lack of information leading to incomplete models even though the preference is intrisically complete?
	
	\subsection{Incompleteness in MCDM}
	Some approaches in MCDM in the family of outranking methods \citep{roy_methodologie_1985, roy_aide_1993, roy_multicriteria_1996, greco_multiple_2016, bouyssou_evaluation_2000, bouyssou_evaluation_2006} permit to represent incomparabilities. A much used idea is to take into account two points of view and accordingly build two weak-orders, $\succeq^1$, $\succeq^2$, then define ${\succeq} = {\succeq^1} ∩ {\succeq^2}$. Thus, when the points of view of the two weak-orders strongly disagree about some pair of objects, the resulting relation does not take position about the related preference. As an example, let us consider (a simplification of) the ELECTRE III method (our description is much simplified because we want to focus on the way incomparabilities may arise). It builds a concordance relation $C$ that determines whether alternative $x$ is sufficiently better than $y$, by accounting only for the criteria in favor of $x$. For example, a model compatible with ELECTRE III could declare that $x C y$ iff $x$ is better than or equal to $y$ according to at least two criteria. It also defines a discordance relation $D$. In ELECTRE III, the performance of $x$ on a given criterion $g$ may be considered as “unacceptably low” compared to the performance of $y$ on $g$ (depending on parameters of the model). For example, a model could consider that the performance of $x$ on $g$ is unacceptably low compared to $y$ iff $y_g - x_g ≥ 2$, where $X_g$ would be numerical. Then define $x \succeq y$ iff $x C y$ and $¬(x D y)$.
	
	Consider an example with $\allalts = \R^3$, each criteria to be maximized, and the following two alternatives: $x = (0, 0, 2), y = (1, 1, 0)$. Using the example definitions given above for $C$ and $D$, we obtain $x C y$ and $x D y$, thus $x$ and $y$ are incomparable in the resulting model.
	
	A recent trends aims at axiomatizing outranking approaches \citep{bouyssou_consolidated_2015}.

	Robust methods in MCDM exist that propose to distinguish conclusions that hold for sure, given some information about the preferences of the DM, and conclusions that possibly hold. Such robust methods typically start from a class of possible models, that represents an assumption about the way the \ac{DM} reasons in problem considered. (For readers used to the machine learning terminology, this corresponds to the version space.) A robust method, given a class of models $M$ that contains all preference relations considered possible a priori, and a set of constraints $C$ (such as examples of comparisons), will consider that $a$ is necessarily preferred to $b$, $a \succeq^N b$, whenever $a \succeq b$ for all relations $\succeq$ in $M$ that satisfy $C$ \citep{greco_ordinal_2008}.
	\begin{example} Assume that the only thing you know about the \ac{DM} is that she prefers $x = (0, 0, 2)$ to $y = (0, 4, 0)$, and you assume that $\succeq$ satisfies preferencial independence, meaning that the way two alternatives compare does not change when changing equal values on a given criterion. Thus, $M$ contains all relations that satisfy preferencial independence, and $C$ is the constraint $x \succ y$. You may then conclude that $a = (3, 0, 2)$ is preferred to $b = (3, 4, 0)$, thus, $a \succ^N b$, but you ignore whether $c = (1, 1, 1)$ is preferred to $d = (0, 2, 2)$, thus, $¬(c \succeq^N d)$ and $¬(d \succeq^N c)$.
	\end{example} 
	Such approach permits to represent incomparabilities. They are used to represent incomparabilities that stem from incomplete knowledge of the analyst, rather than to represent intrinsic incomparabilities.
	
	\subsection{Incompleteness in DMU}
	
	As recalled in Section~\ref{sec:intro}, probability theory and expected utility are the most widely used tools when having to decide under uncertainty, and naturally induce completeness of preferences. It should however be noted early scholars were critical about the fact that completeness could hold in practice, as recalled previously. Many attempts to relax the completeness axioms does so by considerings axioms leading to deal with sets of utilities and sets of probabilities~\cite{aumann_utility_1962}, entangling together aspects about decision and about information modelling. 
	
	\subsubsection{Keeping precise probabilities but not expected utility}
	
	Even when having precise probabilities, there are alternatives to expected utility that induce incomplete preferences. One of them that is particularly interesting is the notion of stochastic dominance~\cite{levy_stochastic_1992}. Assuming that the set of consequences is completely ordered by preference, which we denote by $C = \{c_1, …, c_n\}$ where $c_i$ is preferred to $c_{i - 1}$, then a lottery $p_x$ is said to stochastically dominate $p_y$ iff
	\begin{equation}\label{eq:stodom}P_x(\{c_1,\ldots,c_i\})=\sum_{j=1}^i p_x(c_j) \leq P_y(\{c_1,\ldots,c_i\})=\sum_{j=1}^i p_y(c_j).\end{equation}
	Since Inequality~\eqref{eq:stodom} can be satisfied for some consequence $c_i$ and not for others, possible incomparabilities immediately follow. %It should be noticed that the probabilities $p_1,p_2$ may concern the same uncertain quantity, but may result from the mapping of the original probability $p$ to the space of (ordered) consequences, such as in \cref{exm:DMU}.
	
	\begin{example}
		Consider again the space $C=\{c_1,\ldots,c_3\}$of consequences and the following probability masses (induced by different acts $x_1,x_2,x_3$) defined over them, given in vectorial forms: $p_1=(0.2,0.3,0.5)$, $p_2=(0.1,0.3,0.6)$ and $p_3=(0.3,0,0.7)$. They induce the following cumulative probabilities:
		$$P_1(\{c_1\})=0.2, \; P_1(\{c_1,c_2\})=0.5, \; P_1(\{c_1,c_2,c_3\})=1; $$
		$$P_2(\{c_1\})=0.1, \; P_2(\{c_1,c_2\})=0.4, \; P_2(\{c_1,c_2,c_3\})=1;$$
		$$P_3(\{c_1\})=0.3, \; P_3(\{c_1,c_2\})=0.3, \; P_3(\{c_1,c_2,c_3\})=1, $$
		from which we can conclude that $x_2$ stochastically dominates $x_1$, while $x_3$ is incomparable to both $x_1$ and $x_2$, according to stochastic dominance.
	\end{example}
	
	The notion of stochastic dominance has some very attractive properties, as:
	\begin{enumerate}
		\item it does not necessitate to define utilities over consequences, and merely requires them to be linearly ordered;
		\item it can be be perceived as a criterion allowing for utilities to be ill-defined, as $p_x$ stochastically dominates $p_y$ if and only if $x$ has a higher expected utility than $y$ for any increasing utility function $u$ defined over $C$. 
	\end{enumerate}
	
	\subsubsection{Incompleteness from non-precise probabilities}
	
	In the past few decades, different scholars have challenged the need for precise probabilities associated to classical axiomatics, advocating the use of imprecisely defined prices (expected values) or of imprecisely defined probabilities. To mention but a few:
	\begin{itemize} 
		\item Levi advocates the uses of sets of probabilities within a logical interpretation of probabilities;
		\item Walley extends de Finetti axioms by assuming that an agent would give different buying and selling prices for an act, therefore allowing indecision if the given price is between these two bounds;
		\item Shafer and Vovk explores a probabilistic setting centered on the notion of Martingale.
	\end{itemize}
	Such theories can most of the time be associated to the use convex sets of probabilities, and give rise to decision rules that extend expected utility but do allow incomparabilities. Once we accept that a convex set $\mathcal{P}$ of probabilities (or a formally equivalent representation) can represent our knowledge, incompleteness ensues. 
	
	A prototypical way to induce incompleteness between acts from incompleteness in probabilities is to adapt expected utility criterion, and among rules doing so, maximality is a popular one (it is championed by Walley, but is considered as early as the 60's by Ansombe and Aumann ***papier 63***). Given acts $x_1,x_2$, maximality says that 
	$$x_1 \succ x_2 \textrm{ iff }  u(x_1) ≥ u(x_2) \textrm{for all} p \in \mathcal{P},$$
	still with $u(x) = \sum_{s \in S} p(s) u_1(x(s))$. It is clear that this reduces to expected utility when $\mathcal{P}$	is a singleton. 
	
	\begin{example}
		Going back to Example~\ref{exm:DMU}, we have that 
		$$u(x_1)=p(A) - p(B) \textrm{ and } u(x_1)=p(B) - p(A)$$
		which means that the two acts will be incomparable according to maximality as soon as $\mathcal{P}$ contains a probability where $p(A)=p(B)$ that is not on the border of $\mathcal{P}$ (i.e., it contains at least one mass where $p(A)<p(B)$, and another where $p(B)>p(A)$). 
	\end{example}
	
	It should be noted that other authors have proposed different rules: for instance Levi as well as some of his followers (citer Seidenfeld) recommends to use a decision rule, often called E-admissibility, that does not give rise to an incomplete order between acts, but rather selects all the acts that are Bayes optimal according to at least one probability $p \in \mathcal{P}$. In terms of order, this comes down to consider a set of possible linear ordering, and to retain only those elements that are maximal for at least one of them. 
	
	%Compared to maximality, E-admissibility implicitly uses the precise probabilities within the set $\mathcal{P}$, and therefore would not be consistent with Walley's view where the bounded (buying and selling) prices are not to be interpreted as incomplete information about an ideal precise price, but have to be considered as current state of knowledge that may not be reducible with additional information. 
	
	\commentSD{Effectivement, j'unifierais les deux suivantes en mettant working with sets of probabilities and utilities}
	\subsubsection{Working with sets of utilities}
	
	\citet{dubra_expected_2004} represents preferences over lotteries by means of a set of real-valued utility functions. Preference holds whenever the expected utility for the preferred alternative is higher, for all utility functions in the set. This idea has also been applied in other contexts \citep{ok_utility_2002, eliaz_indifference_2006}.
	
	\citet{dubra_model_2002} propose to view the preference relation as a completion of an intuitive partial preference relation: the \ac{DM} knows intuitively the result of some comparisons, and compute the other ones by applying some reasoning process. They also obtain a preference relation that is representable using a set of utility functions. Observe that this approach directly tackles some of the shortcomings described in \cref{sec:empirical}.
	
	\citet{manzini_representation_2008} use a utility function and a vagueness function, thus, represent the preference using intervals of utilities rather than real valued utilities. (Beyond DMU, also using this representation, \citet{masatlioglu_rational_2005} assume that a specific alternative called the status quo alternative is prominently chosen whenever the \ac{DM} faces a choice about which incomparability occur.)
	
	\subsubsection{Working with sets of probabilities and utilities}
	
	\commentOC{Je proposerais de fusionner cette § avec la précédente, à moins que tu aies beaucoup de choses en tête à dire à ce sujet ? (Moi pas !)}
	\citet{galaabaatar_subjective_2013} are interested in the Savage-like context where probabilities are unknown and represent an incomplete preference relation in uncertaintly using a set of pairs of probabilities and utilities.
	
	\subsubsection{Others}
	\citet{aumann_utility_1962}: axioms do not require completeness. $x \succeq y ⇒ u(x) ≥ u(y)$ and $x \succ y ⇒ u(x) > u(y)$ but the reverse implications do not hold.

	\citet{danan_are_2006} propose to consider that an incomparability is observed whenever the \ac{DM} is ready to pay a small price to postpone the decision, without receiving new information about the problem.
	
\citet{deparis_when_2012} studies behavior of individuals how are allowed to express incomparability supplementary to indifference or preference.

	\subsection{Incompleteness: absence of knowledge or knowledge of absence?}
%	
%	\section{Dropping transitivity}
%	
%	\subsection{Empirical evidences of intransitivity}
%	
%	\subsection{Under a normative view}
%	Fishburn is one of the prominent advocate about intransitivity holding even under normative approaches. Explain arguments…
%	
%	Roy has very much insisted on incomparability being taken into account explicitly in preference modeling. Explain…
%	
%	\subsection{Approaches that admit intransitivity in MCDM}
%	
%	\subsection{Approaches that admit intransitivity in MDU}
%	
%	* Statistical preferences, strongly related to the Condorcet paradox in social choice theory
%	
%	\subsection{Intransivity: a default to be repaired, or a fact to be modelled?}
	
\bibliography{Survey}

\end{document}
