\RequirePackage{amsmath}
%\RequirePackage[l2tabu, orthodox]{nag}
\documentclass[french, english]{llncs}
\input{preamble/packages}
\input{preamble/math_basics}
\input{preamble/math_mine}
\input{preamble/redac}
\input{preamble/draw}
\input{preamble/acronyms}
\newcommand{\dollars}[1]{\SI{#1}[\$]{}}
\newcommand{\simplebet}[3]{(\dollars{#1}, #2; \dollars{#3})}

\begin{document}
%Reasons and means for modeling preferences as incomplete.
	\title{Preference models that relax completeness: why, how?}
	\author{Olivier Cailloux\inst{1} \and Sébastien Destercke\inst{2}}
	\institute{
		LAMSADE\\
		\email{olivier.cailloux@dauphine.fr}
		\and HDS
	}
	\hypersetup{
		pdfsubject={preference modeling},
		pdfkeywords={keyw1, keyw2}
	}
	\maketitle
	
	\abstract{Literature involving preferences of artificial agents or human beings often assume their preferences can be represented using a complete transitive binary relation. Much has been written however on more complex, or more interesting, models of preferences. In this article we review some of the reasons that have been put forward to justify more complex modeling, and review some of the techniques that have been proposed to obtain models of such preferences.}
	
	%Oddly enough, llncs class seems to set the indent to zero when typesetting the abstract.
	\setlength{\parindent}{1.5em}
	
	\section{Introduction}\label{sec:intro}
	Preferences of agents are usually assumed to be linear, that is complete, transitive and antisymmetric, or representable with a weak order (a complete and transitive binary relation). In practice, such assumptions limit the scope of preference models one can consider as legitimate, and are also falsified by observed empirical evidences. While models relaxing antisymmetry to allow indifference (relaxing antisymmetry) between options have been around for some time, models relaxing the assumptions of completeness or transitivity are more recent.
	
	There are two canonical fields where the modelling of preferences is a central topic: choosing an alternative when it is evaluated according to different aspects (a.k.a. multi-criteria decision making, or MCDM), and picking an alternative whose quality depends on states of the world that are uncertainly known. Although the two frameworks are formally similar to some extent, they also present some conceptual key differences. 
	
	In MCDM, the common assumption is that the alternatives, i.e., the state of the world is known without ambiguity, and the difficulty is to determine what are the user preferences over these different, but well-defined states. In decision making under uncertainty (DMU), the preferences of the user are usually assumed to be well-known, or at least to have been previously assessed in the form of utility functions, and the problem is to recommend an alternative given our uncertainty about the world. 
	
	In this paper, we will review some reasons to relax preference completeness and models (either in MCDM or DMU) that do so. Although this review will not be comprehensive, it will provide a sufficient number of pointers for the reader to get an overall idea. Given the space limitations, we will also not deal in details with the issue of transitivity. We will first review MCDM and DMU settings considering completeness in Section~\ref{sec:review}, before detailing how completeness can be perceived in descriptive and normative approaches (recalling their difference at the same time) in Section~\ref{sec:nordesc}. Finally, we review models that departs from completeness in Section~\ref{sec:incomp}.
	

	
	\section{Completeness in classical and less classical settings}\label{sec:review}
	In this section, we are going to recall the main models that consider completeness and transitivity of preferences as a consequence of natural requirements, if not as pre-requisite of any preference modelling. We will also recall normative views and descriptive views of these concepts. 
	
	\subsection{MCDM}
	In MCDM, the classical approach is to assume that the alternatives are evaluated using a set of criteria $\crits$, each having an evaluation scale $X_g$. The set of all possible alternatives is $\allalts = \prod_{g \in G} X_g$, that is, every combination of evaluations are considered possible. 
	We are interested in a preference relation $\succeq$ defined as a binary relation over $\allalts$.
	
	\begin{example}
		Say the \ac{DM} must choose what to plant in her garden. The set of alternatives $\allalts$ are all possible vegetables, the criteria $\crits = \{g_1, g_2, g_3\}$ measure the taste, quantity, and price of each vegetable, and $\alts \subseteq \allalts$ are the vegetables that are available this year for planting. $X_{g_1} = \{A, B, C, D\}$, a set of labels, with $x_1$ representing the taste of the vegetable $x \in \allalts$ as considered by the \ac{DM} ($A$ is the worst taste, $D$ the best), $X_{g_2} = [0, 100]$, with $x_2$ representing the number of meals that the \ac{DM} would enjoy if deciding to plant $x$, and $X_{g_3} = \R$, where $x_3$ indicates the price to pay for planting $x$.
	\end{example}
	
	Typical approaches in MCDM assume that there is some real-valued function $v: \allalts \to \R$ mapping alternatives to their values, and that $x \succeq y$ iff  $v(x) ≥ v(y)$.
	
	\subsection{DMU}
	In the simplest form of DMU considered here (SDMR, for Simple Decision Making under Risk), we consider a set $S$ of possible states of the world, a finite set of consequences $C$, and each act $x: S \to C$ is modeled as a function where $x(s)$ is the consequence of performing $x$ when $s$ is the actual state of the world. Define $\allalts$ in this case as the set of possible acts (thus $\allalts = C^S$).
	In SDMR, uncertainty is modeled by a probability measure $p$ over the power set of $S$, $\powerset{S}$, thus with $p(s) \in [0, 1]$ indicating the probability of occurence of $s$ (with $s \subseteq S$), and $p(S) = 1$. 
	We consider a preference relation $\succeq$ defined as a binary relation over $\allalts$.
	Given an act $x$ and a probability measure $p$, it is usually convenient to view $x$ as $p_x$, a probability mass over the consequences: define $p_x: C → [0, 1]$ as $p_x(c) = p(x^{-1}(c))$, where $x^{-1}(c)$ designate the set of states in which $x$ leads to the consequence $c$. Such a $p_x$ is usually called a lottery. In most numerical DMU frameworks, a utility function $u_1: C → \R$ mapping consequences to numbers is assumed (or derived), from which is then induced the classical expected utility criterion $u: \allalts → \R$ that represents the global utility of an act and that reads $u(x) = \sum_{s \in S} p(s) u_1(x(s))$. An act $x$ is then preferred to $y$ ($x \succeq y$) iff $u(x) ≥ u(y)$. 
	
	%It follows from this definition that $u$ and $u_1$ are coherent, in the following sense: given an act $x$ that brings a consequence $c$ with probability one, $u(x) = u_1(c)$.
	
	\begin{example}\label{exm:DMU}
		Assume you want to go out and wonder about the weather state ($S=\{A,B,C,D\}$), going from $A=$``shiny" to $D=$``stormy". Given this state, two actions are $x_1$: ``leave the umbrella home" and $x_2$: ``take the umbrella", and the consequences are $c_1$: ``unhappy", $c_2$: ``neither happy nor unhappy" and $c_3$: ``happy". If the weather is nice ($x_1(A)=c_3,x_2(A)=c_1$), not having an umbrella is enjoyable,  and having to bear one for nothing will make you unhappy. On the contrary, if it is stormy ($x_1(D)=c_1,x_2(D)=c_3$), you will be happy to have taken your umbrella, but quite unhappy if you end up wet. In the other situations, you are quite indifferent to both actions. Assuming that $p(A)=0.2, p(D)=0.6$, $p(B)=p(C)=0.1$, and that $u_1(c_i)=i-2$, we then have
		$$u(x_1)=0.2 \cdot 1 + 0.6 \cdot -1 <  u(x_2)=0.2 \cdot -1 + 0.6 \cdot 1$$
	\end{example}
	
	Expected utility has been justified axiomatically by different authors, the main ones being Savage~\cite{savage_foundations_1972}, De Finetti~\cite{definetti_probability_2017} and Von Neumann Morgenstern~\cite{von_neumann_theory_2004}. It is worth noticing that these settings are quite different.
	\begin{itemize}
		\item In De Finetti setting, utilities are given as random variables, and a precise price can be associated to each random variable. That reasoning should be probabilistic and choices made according to expected utility follow from two axioms: linearity and boundedness of those prices.
		\item von Neumann and Morgenstern postulate conditions on $\succeq$ ensuring that utility functions $u$ and $u_1$ satisfying the above conditions exist. The axioms assume completeness of the preferences, and the probabilities are assumed to be given.
		\item In Savage setting, both probabilities and expected utility follow from axioms about preferences between acts. In particular, the first axiom (P1) is that any pair of act should be comparable. Completeness is therefore postulated in the axioms, and expected utility and probabilistic reasoning follow from it. 
	\end{itemize}
	While these theoretical constructs have set very strong foundations for the use of probabilities, in practice experiments such as the Ellsberg urn (contradicting Savage sure-thing principle) suggest that people do not always act according to expected utility. 
	
	Since then, many different extensions have been proposed, some modifying the utilities~\cite{wakker_prospect_2010} or the probabilities~\cite{quiggin_generalized_2012}. Others simply propose to relax the probabilistic assumption, for instance by considering a possibilistic setting  (see~\cite{dubois_qualitative_2003}, that discusses Savage-like axioms), by considering sets of probabilities such as in decision under ambiguity~\cite{gajdos_attitude_2008}, or by simply considering completely missing information, such as Wald's~\cite{wald_statistical_1992} celebrated maximin criterion. 
	
	Such extensions address some of the observed behaviours deviating from expected utility, but keep assuming that all acts are comparable, i.e., that preferences are complete. Yet, if one considers that probabilities or utilities may be incompletely known, the next step is to consider that preferences as well could be.
	
	All models presented or advocated thus far assume that it is possible to order alternatives according to their value, as given by a real function. Thus, they require $\succeq$ to be complete and transitive (by which we mean that if $\succeq$ is incomplete or not transitive, then no suitable function exists).
	
	The two contexts we have introduced, multiple criteria and risk, use as a basis the notion of a preference relation. We need to say a word about what those preferences really represent and what the goal of modeling those may be. This is required to give meaning to discussion about which conditions are reasonable to postulate about $\succeq$, and how to check whether they hold.
	
	\section{Completeness in descriptive and normative approaches}\label{sec:nordesc}
	\subsection{Descriptive approach}
	In the descriptive approach to preferences, the goal of the model is to reflect the observed behavior of a \ac{DM}. Typically, a set of sample choices of the \ac{DM} is first collected, say, of choices of food products in his favorite store, and we would then try to obtain the model that best reflects his choice attitude. Or, we would query an individual’s preference about pairs of objects, and then try to build a predictive model on the whole set of possible pairs of alternatives (a method called active learning in the machine learning community). Such a model may be used to predict his behavior, e.g. for marketing or regulation purposes. In those cases where its purpose is to replace the \ac{DM} by automatic choices, it is debatable whether the normative approach would not be better suited.
	
	Here is what von Neumann and Morgenstern (vNM) say about the preference relation:
	“It is clear that every measurement --- or rather every claim of measurability --- must ultimately be based on some immediate sensation\ldots
	%, which possibly cannot and certainly need not be analyzed any futher.
	%[Such as the sensations of light, heat, muscular effort, etc., in the corresponding branches of physics.] 
	In the case of utility the immediate sensation of preference\ldots%--- of one object or aggregate of objects as against another --- 
	provides this basis\ldots %(3.1.2) (The square brackets indicate a footnote.)
	Let us for the moment accept the picture of an individual whose system of preferences is all-embracing and complete\ldots%, i.e. who, for any two objects or rather for any two imagined events, possesses a clear intuition of preference. More precisely
	 we expect him, for any two alternative events which are put before him as possibilities, to be able to tell which of the two he prefers.” %(3.3.2) (The “events” here correspond to what we call alternatives.)
	
	As the preference relation is considered basic under a purely descriptive approach, the preference itself should be easily observable, and uncontroversial. This permits to empirically test conditions postulated on $\succeq$. Either by asking the individual what she prefers (in which case we “observe” her answer), or by presenting a choice set and observing what she picks from that set (in real life or in a laboratory experiment). In the first case, we have however to be clear about what is meant by “prefers”, which is a reason why many experimenters prefer to go for the latter strategy.
	
	\subsection{Normative approach}
	Under the normative approach, the goal is to model on how the \ac{DM} ought to choose rationally. Rationality may corresponds to accepted external norms (axioms), or to rules accepted by the \ac{DM} after careful thinking. Hence, the decision outcome using such approach may differ from empirically observed decisions. Consider as an example a recruiter in an enterprise who wants to model the recruitment procedure. After having collected data, it may appear that for some (possibly unconscious) reason, the recruitment is biased against some particular socio-economic category. The \ac{DM} may then want to find a recruitment strategy that avoids such biases, therefore actively trying to build a model contradicting empirical observations. 
	
	%It may be, further, that the \ac{DM} himself is not happy about this situation. Thus, he may try to find a strategy of selecting employees that would avoid such biases, therefore actively trying \emph{not} to build a perfectly descriptive model of the normal selection attitude.
	
	When the focus is on providing decision help to a \ac{DM} by letting him think about the norms he prefers, rather than considering them as external rationality norms, %that he ought to follow under threat of being considered irrational, 
	the approach is often termed prescriptive, or constructive. Carefully and formally defining such terms is important, especially as different authors use them somewhat differently \citep{roy_decision_1993, tsoukias_concept_2007}. As we do not want to focus on such issues, we will use the term normative as an umbrella.

 %\commentSD{Raccourcir/enlever des citations?}
 \citet{mcclennen_rationality_1990, guala_logic_2000} discuss philosophical grounds for accepting a normative model. \citet{anand_are_1987, mandler_difficult_2001} discuss normative grounds for usual axioms about preferences, including completeness.
	
	What is the best approach to adopt is not always obvious. For instance recommender systems often adopt a descriptive approach, mimicking choice behaviour to increase profit, for example. Yet, such an approach reflect our cognitive limitations, and it is not clear that a more thoughtful or normative-oriented (at least partially) process would not lead to more satisfying, diverse or surprising recommendations that may moreover be explainable.
	
	%When building recommender systems in the literature in artificial intelligence, the focus is often on descriptive approaches. This is usually left implicit, with no discussion about possible alternatives. We think however that an interesting path is offered by normative approaches. Descriptive approaches will, by design, reflect cognitive limitations exhibited by us, normal human beings. Those limitations are numerous and sometimes obviously not in agreement with what a more thoughtful and knowledgeable person would do, as is well known and will be illustrated in this article (although there is debate about how such a sentence is to be interpreted exactly, more about this later). Providing (more) normative-based automatic recommendations might help provide sound advices, help increase serendipity, and possibly reduce incitations to merchants to exploit imperfections on the human reasoning abilities by using marketing techniques that may lead to choices that the \ac{DM} himself would possibly reject when thinking more carefully. (As an old but known example, “the credit card lobby is said to insist that any price difference between cash and card purchases should be labeled a cash discount rather than a credit surcharge.” \citep{tversky_rational_1986}.) 
	
	%\commentSD{La phrase suivante me parait un peu mal s'agencer avec le reste?}
	%\citet{fischhoff_knowing_1980} \citep[also]{fischhoff_knowing_1988} discuss possible attitudes of an analyst wanting to take into account incompleteness of preferences.
	

	\section{Dropping completeness}\label{sec:incomp}
	
	
	\subsection{Defining and testing incompleteness}
	\label{sec:empirical}
	A first step to define and test incompleteness in preferences is to define what is meant by preference and by the relation $\succeq$, as its everyday useag can be ambiguous:\citet{frankfurt_freedom_1971} gives seven interpretations of “to want to”, and this exercice transposes, \emph{mutatis mutandis}, to the notion of preference.
	
	Expanding on vNM, we define that the \ac{DM} \emph{prefers} $a$ to $b$ when expressing an intuitive attraction towards $a$ when presented with $a$ and $b$, or an equal attraction towards $a$ and $b$; and this attraction does not change along a reasonable time span and as well as when irrelevant changes in the context happen. %The second part of our definition makes it applicable also in case the intuitive attraction felt by the \ac{DM} changes for no apparent reason, or depends on the context at the moment of presenting $a$ and $b$ to the \ac{DM}, for example whether it is currently raining. 
	Here, we assume that $a, b$ are alternatives in $\allalts$ described by their evaluations on the criteria (in MCDM) or by the relevant probability distributions and consequences (in SDMR), and consider as irrelevant changes anything that does not change those descriptions. 
	Under this definition, postulating completeness of $\succeq$ amounts to say that choices of the \ac{DM} will not change along time or when irrelevant changes happen. While this is not the only possible definition (others will be mentioned), it appears reasonable and sufficiently formal to make the condition empirically testable.
	
	A first, immediate argument against completeness is that preferences are not stable over time, a well-accepted fact in experimental psychology. Quoting \citet{tversky_intransitivity_1969}, individuals “are not perfectly consistent in their choices\ldots%. When faced with repeated choices between x and y, 
	people often choose x in some instances and y in others. Furthermore, such inconsistencies are observed even in the absence of systematic changes in the decision maker’s taste\ldots %which might be due to learning or sequential effects. It seems, therefore, that the observed 
	inconsistencies reflect inherent variability\ldots %or momentary fluctuation 
	in the evaluative process.” This argument alone would not be strong enough, at least from a normative standpoint, as we may consider that underlying preferences are complete, but that choices are noisy observations of such preferences. 
	
	However, a second argument also inherited from empirical psychology is that preferences may change in a non-random, consistent way according to changes in the presentation of the alternatives or the context that should have no impact from a normative point of view. 
	
	%This argument may not be strong enough however. In absence of other arguments, one might agree that preferences are in reality incomplete but claim that they may appropriately be \emph{modeled} as complete: a model of complete preferences would simply deviate from time to time from what individuals declare because of (perhaps rare) random fluctuations in their expressions of preferences. 
	%In order to discuss this hypothesis, we turn to the second (and much more interesting) reason for failure of completeness, which is also brought by the literature in empirical psychology. It appears that preferences change may not be attributed solely to random fluctuations: they change in systematic ways according to changes in the presentation of the alternatives or the context that should have no impact from a normative point of view.
	
	Let us also note that \citep[p. 630]{von_neumann_theory_2004} themselves considered completeness as a strong condition: “it is very dubious, whether the idealization of reality which treats this postulate as a valid one, is appropriate or even convenient”.

	\subsection{Empirical evidence of incompleteness}
	
	In multicriteria contexts, psychologists have shown systematic differences between the so-called choice and matching elicitation procedures \citep{tversky_contingent_1988}. Assume you want to know which of two alternatives $x, y$ the \ac{DM} prefers, in a problem involving two criteria. You can present both and directly ask for a choice. Alternatively, the matching procedure consists in presenting $x$ with its two evaluations $g_1(x), g_2(x)$, and present $y'$ with only $g_1(y') = g_1(y)$, and ask the \ac{DM} for which value $g_2(y')$ $y'$ would be indifferent to $x$. Assuming $\succeq$ satisfies dominance and transitivity, you then know that $x \succeq y$ iff $g_2(y') ≥ g_2(y)$. The authors confirm the prominence hypothesis stating that the more prominent criterion has more importance in choice than in matching. One of their study confront the subject to a hypothetical choice between two programs for control of a polluted beach. Program $x$ completely cleans up the beach at a yearly cost of \dollars{750 000}; program $y$ partially cleans it up for a yearly cost of \dollars{250 000}. They assume that pollution is the more prominent criterion here, hence expect that $x$ will be chosen more often in choice than in matching. Indeed, 48\% out of the 104 subjects confronted with a choice procedure selected $x$, whereas only 12\% out of the 170 subjects selected it in a matching procedure. Note that similar studies hold for lotteries in SDMR~\citep{luce_utility_2000}.
	
%	\citet{maccrimmon_real_1980} have collected preferences of individuals over alternatives in a risk setting, representing monetary bets. Their subjects are business executives. One of the most striking result of the study is that individuals order some pairs of alternatives differently depending on which other alternatives they are presented with. The study is run as follows. Each subject is presented instructions and three sets of five alternatives. (The same three sets of five alternatives are presented to every individual.) The subjects are asked to rank each alternative by order of preference. Each alternative has exactly two possible consequences (monetary outcomes), and can thus be fully described using three numbers: best outcome, probability of winning the best outcome, and worst outcome. We focus on two of these sets of five alternatives, labelled set B and C in the paper. Set B contains the alternatives $\simplebet{5}{1}{5}$, $\simplebet{20}{0.692}{3.90}$, $\simplebet{20}{0.2752}{-0.70}$, $\simplebet{20}{0.6185}{-19.30}$, $\simplebet{20}{0.9046}{-137.00}$. Set C contains $\simplebet{5}{1}{5}$, $\simplebet{10}{0.6185}{-3.10}$, $\simplebet{15}{0.6185}{-11.20}$, $\simplebet{20}{0.6185}{-19.30}$, $\simplebet{25}{0.6185}{-27.40}$. Observe that those sets contain the same first and fourth alternatives. However, 9 out of 40 subjects give those pairs of alternatives different relative positions depending on which set they are ranking (4 of them rank B1 above B4 but C4 above C1, and vice-versa for the other 5). This effect might be thought to be due to the individuals not taking the task seriously, or be attributed to random fluctuations. But as the authors note, this appears implausible because of the very regular choice patterns observed in the rest of the analysis.
	
	%Similarly, in context of DMR, preferences between loteries may be elicited using questions about probability equivalent loteries, or about certainty equivalents. Systematic differences appear in the preferences exhibited between each mode of questioning \citep{luce_utility_2000}.
	
	This phenomenon is known as preference reversal due to a breach of procedure invariance. Another reversal is the one due to description invariance (or framing effect), showing that preferences can change by changing alternative descriptions. In \citet{tversky_framing_1981}, two groups have to choose a  program to prepare against an epidemic outspring that would result otherwise in 600 deaths. The two groups are presented with the same numeric alternatives $x$ and $y$, but on the first group the alternatives is presented in terms of numbers of life saved, while in the second they are presented in terms of death counts. The experiment shows that preferences are consistently different in the two groups. It is indeed well-known that losses and gains, even if identical, are perceived differently \citet{thaler_toward_1980}.
	
 %The first group must choose between program $x$, which saves 200 persons, and program $y$, which saves 600 persons with 1 chance on 3, and otherwise saves nobody. Most persons in that group choose program $x$. The second group must choose between program $x'$, which lets 400 persons die, and $y'$, which results in nobody dying with 1 chance on 3, and otherwise the death of 600 persons. Most persons in the second group choose program $y'$. Observe that both choices are identical up to phrasing. Indeed, it is well-known in psychology that choices phrased as losses are evaluated differently than choices phrased as gains \citet{thaler_toward_1980}.
	
	Numerous other studies exist that show and discuss preference reversal effects \citep[Ch. 2]{deparis_etude_2012}, \citep{lichtenstein_construction_2006, tversky_causes_1990, kahneman_judgement_1981, kahneman_choices_2000}. How to best account for and predict preference reversals is still debated, but their existence is consensual \citep{wakker_prospect_2010, birnbaum_empirical_2017}. Some skeptic did try to show that preference reversals could be attributed to deficiencies in the design of the studies or lack of realism, but finally came around \citet{slovic_preference_1983}.
		
	This shows that the $\succeq$ relation cannot be expected to be complete given our definition. For some alternatives, individuals may be led to declare different preferences, denoting an absence of a clear, intuitive preference for each pairs of alternatives. This has been studied empirically \citep{slovic_who_1974, maccrimmon_utility_1979, lichtenstein_reversals_2006}, and \citet[pp. 101 – 103]{savage_foundations_1972} famously reported that it happened to him. Luckily, preference reversals are not universal \citep[p. xvi]{lichtenstein_construction_2006}: individuals preferences are not entirely manipulable.
	
	%do not have a clear, intuitive preference for each pairs of alternatives, but rather, at least for some of them, can be lead to declare preference for one, depending on how the problem has been presented. When thinking more about the comparison and presented with different views of the same problem, individuals may in some cases change their preference. This has been studied empirically \citep{slovic_who_1974, maccrimmon_utility_1979, lichtenstein_reversals_2006}, and \citet[pp. 101 – 103]{savage_foundations_1972} famously reported that it happened to him. 

	One may of course want to preserve completeness of preferences, for example to preserve mathematical and computational simplicity. One way to do so, common in experimental psychology, is to restrict further the frame in which preferences are considered. For instance, \citet{luce_utility_2000} indicates clearly that he studies preferences in terms of choice, not judgment; \citet{maccrimmon_real_1980} excludes some kind loteries from the scope of the model. In such cases, completeness may well be justified, at the price of losing generality. In other settings, such as normative approaches or recommender systems, it is unclear that such reductions should be enforced, as they may lead to constraints or axioms that may appear unnatural to the user, or hard to impose in practice. 
	
	Note that in such experiments, incomparability is actually not observed \emph{per se}, as experimental protocol forces to make a choice. Some other studies \citet{deparis_when_2012} are interested in the behavior of individuals when they are allowed to make explicit statements of incomparability. Others such  \citet{danan_are_2006} propose to consider that an incomparability is observed whenever the \ac{DM} is ready to pay a small price to postpone the decision.


%One way wish however to model a preference relation as complete anyway, in order, for example, to benefit from increased simplicity, tractability, or mathematical elegance of such models. One path for doing this is to consider the context as fixed, for example, consider the way of presenting the alternatives to the \ac{DM} as fixed. Thus, for example, the model would represent the preference as stated by the \ac{DM} when asked questions in terms of choices, and not when he is interrogated in terms of matching. Furthermore, the model would represent not a preference understood as the expression of clear intuitive attraction from the \ac{DM} towards some alternative, but rather as the a noisy intuitive attraction, known only imperfectly by the \ac{DM}. 
%	In some cases, this is a perfectly reasonable path to follow. This strategy is commonly followed in experimental psychology, for example, \citet{luce_utility_2000} indicates that his book is about studying preferences in terms of choice and not of judgment; \citet{maccrimmon_real_1980} indicates that some kind of loteries should not be considered to belong to the scope of the model. We of course do not claim that models of preference relations that assume completeness have no validity whatsoever, as the validity of a model depends on its purposes. 



%In the case however not of psychologists but of researchers building recommender systems, it is unclear that this path should be systematically followed. Indeed, in some cases we may want the recommendations of the recommender system to be invariant to the particular details about how alternatives have been presented to the individual. Not only because we may not know how the alternatives have been presented (what the context is), but more fundamentally, because the individual may find the advices of a recommender system more sound if it is independent of minute details of the context. (Adopting this view of course makes the system closer to the normative approach.)
	
	%These effects of preference reversals are of course not everywhere \citep[p. xvi]{lichtenstein_construction_2006}. You can’t make someone choose whatever you want just by presenting it in the right way. (Or, at least, and luckily, we do not yet know how to do that.) Thus, another way of viewing the experimental highlights discussed here above is that a more meaningful model may be built on some subset of pairs that exhibit a stable preference. By forcing completeness in the model, we may build models that are partly irrelevant to the perception of the \ac{DM} we try to help: for some pairs of alternatives, there may be no sensible way, even conceptually, to determine which alternative is really preferred by the \ac{DM}.
	
	Above experiments suggest that incomparability may be, to some extent, an intrinsic property of individuals preferences. Yet, even when assuming completeness of preferences, for example in normative view, it may well be that provided information is insufficient to obtain a fully precise models, in which case incompleteness can be due to an incompletely specified model. 
	
	\subsection{Incompleteness in MCDM}
	Some approaches in MCDM in the family of outranking methods \citep{roy_multicriteria_1996, greco_multiple_2016, bouyssou_evaluation_2000, bouyssou_evaluation_2006}, which are in the process of being axiomatized \citep{bouyssou_consolidated_2015}, can represent incomparabilities. A much used idea is to take into account two points of view leading to weak-orders $\succeq^1$ and $\succeq^2$, then define ${\succeq} = {\succeq^1} ∩ {\succeq^2}$. Thus, when the two weak-orders strongly disagree about some pair of objects, the result can declare them incomparable. As an example, consider (a simplification of) the ELECTRE III method (our much simplified description only consider the aspects sufficient to obtain incomparabilities). It builds a concordance relation $C$ that determines whether alternative $x$ is sufficiently better than $y$, by accounting only for the criteria in favor of $x$. For example, a model could declare that $x C y$ iff $x$ is better than or equal to $y$ for at least two criteria. It also defines a discordance relation $D$. In ELECTRE III, the performance of $x$ on a given criterion $g$ may be considered as “unacceptably low” compared to the performance of $y$ on $g$. For example, a model could consider that $x$ is unacceptably low compared to $y$ on $g$ iff $y_g - x_g ≥ 2$, where $X_g$ would be numerical. Then define $x \succeq y$ iff $x C y$ and $¬(x D y)$.
	
	Consider an example with $\allalts = \R^3$, each criteria to be maximized, and the following two alternatives: $x = (0, 0, 2), y = (1, 1, 0)$. Using the relations $C$ and $D$ defined above, we obtain $x C y$ and $x D y$, thus $x$ and $y$ are incomparable in the resulting model. Such approaches tend to consider incomparabilities as intrinsic to the system, since even a completely specified model could lead to incomparabilities. 

	Robust methods in MCDM exist that distinguish conclusions (i.e.,preferences) that hold for sure, given limited preferential information from the \ac{DM}, from conclusions that possibly hold. Such methods typically start from a classe $M$ of possible models (equivalent to version or hypothesis spaces in machine learning) assumed to represent the \ac{DM} preferences. A robust method, given a class $M$ and a set of constraints $C$ reducing the set of possibles models (typically preference statements of the \ac{DM}), will consider that $a$ is necessarily preferred to $b$, $a \succeq^N b$, whenever $a \succeq b$ for all relations $\succeq$ in $M$ that satisfy $C$ \citep{greco_ordinal_2008}.
	\begin{example} Assume that the only thing you know about the \ac{DM} is that she prefers $x = (0, 0, 2)$ to $y = (0, 4, 0)$, and you assume that $\succeq$ satisfies preferencial independence, meaning that the way two alternatives compare does not change when changing equal values on a given criterion. Thus, $M$ contains all relations that satisfy preferencial independence, and $C$ is the constraint $x \succ y$. You may then conclude that $a = (3, 0, 2)$ is preferred to $b = (3, 4, 0)$, thus, $a \succ^N b$, but you ignore whether $c = (1, 1, 1)$ is preferred to $d = (0, 2, 2)$, thus, $¬(c \succeq^N d)$ and $¬(d \succeq^N c)$.
	\end{example} 
Such approaches consider that incomparabilities follow from a lack of knowledge, and are not intrinsic to the modelled preference relation, as in principle one could collect enough constraints $C$ about $M$ to identify a unique model (or a set of model leading to only one possible relation $\succ$ on a set of alternatives).
	
	\subsection{Incompleteness in DMU}
	
	As recalled in Section~\ref{sec:intro}, probability theory and expected utility are the most widely used tools when having to decide under uncertainty, and naturally induce completeness of preferences. It should however be noted early scholars were critical about the fact that completeness could hold in practice, as recalled previously. Many attempts to relax the completeness axioms does so by considerings axioms leading to deal with sets of utilities and sets of probabilities~\cite{aumann_utility_1962}, entangling together aspects about decision and about information modelling. 
	
	\subsubsection{Keeping precise probabilities but not expected utility}
	
	Even when having precise probabilities, there are alternatives to expected utility that induce incomplete preferences. One of them that is particularly interesting is the notion of stochastic dominance~\cite{levy_stochastic_1992}. Assuming that the set of consequences is completely ordered by preference, which we denote by $C = \{c_1, …, c_n\}$ where $c_i$ is preferred to $c_{i - 1}$, then a lottery $p_x$ is said to stochastically dominate $p_y$ iff
	\begin{equation}\label{eq:stodom}P_x(\{c_1,\ldots,c_i\})=\sum_{j=1}^i p_x(c_j) \leq P_y(\{c_1,\ldots,c_i\})=\sum_{j=1}^i p_y(c_j).\end{equation}
	Since Inequality~\eqref{eq:stodom} can be satisfied for some consequence $c_i$ and not for others, possible incomparabilities immediately follow. %It should be noticed that the probabilities $p_1,p_2$ may concern the same uncertain quantity, but may result from the mapping of the original probability $p$ to the space of (ordered) consequences, such as in \cref{exm:DMU}.
	
	\begin{example}
		Consider again the space $C=\{c_1,\ldots,c_3\}$of consequences and the following probability masses (induced by different acts $x_1,x_2,x_3$) defined over them, given in vectorial forms: $p_1=(0.2,0.3,0.5)$, $p_2=(0.1,0.3,0.6)$ and $p_3=(0.3,0,0.7)$. From those, it can be checked that
%		 They induce the following cumulative probabilities:
%		$$P_1(\{c_1\})=0.2, \; P_1(\{c_1,c_2\})=0.5, \; P_1(\{c_1,c_2,c_3\})=1; $$
%		$$P_2(\{c_1\})=0.1, \; P_2(\{c_1,c_2\})=0.4, \; P_2(\{c_1,c_2,c_3\})=1;$$
%		$$P_3(\{c_1\})=0.3, \; P_3(\{c_1,c_2\})=0.3, \; P_3(\{c_1,c_2,c_3\})=1, $$
	 that $x_2$ stochastically dominates $x_1$, while $x_3$ is incomparable to both $x_1$ and $x_2$, according to stochastic dominance.
	\end{example}
	
	The notion of stochastic dominance has some very attractive properties, as:
	\begin{enumerate}
		\item it does not necessitate to define utilities over consequences, and merely requires them to be linearly ordered;
		\item it can be be perceived as a criterion allowing for utilities to be ill-defined, as $p_x$ stochastically dominates $p_y$ if and only if $x$ has a higher expected utility than $y$ for any increasing utility function $u$ defined over $C$. 
	\end{enumerate}
	
	\subsubsection{Incompleteness from non-precise probabilities}
	
	In the past few decades, different scholars have challenged the need for precise probabilities associated to classical axiomatics, advocating the use of imprecisely defined prices (expected values) or of imprecisely defined probabilities. To mention but a few:
	\begin{itemize} 
		\item Levi~\cite{levi_enterprise_1983} advocates the uses of sets of probabilities within a logical interpretation of probabilities;
		\item Walley~\cite{walley_statistical_1991} extends de Finetti axioms by assuming that an agent would give different buying and selling prices for an act, therefore allowing indecision if the given price is between these two bounds;
		\item Shafer and Vovk~\cite{shafer_probability_2005} explores a probabilistic setting centered on the notion of Martingale.
	\end{itemize}
	Such theories can most of the time be associated to the use convex sets of probabilities, and give rise to decision rules that extend expected utility but do allow incomparabilities. Once we accept that a convex set $\mathcal{P}$ of probabilities (or a formally equivalent representation) can represent our knowledge, incompleteness ensues. 
	
	A prototypical way to induce incompleteness between acts from incompleteness in probabilities is to adapt expected utility criterion, and among rules doing so, maximality is a popular one (it is championed by Walley, but is considered as early as the 60's~\cite{aumann_utility_1962}). Given acts $x_1,x_2$, maximality says that 
	$$x_1 \succ x_2 \textrm{ iff }  u(x_1) ≥ u(x_2) \textrm{for all} p \in \mathcal{P},$$
	still with $u(x) = \sum_{s \in S} p(s) u_1(x(s))$. It is clear that this reduces to expected utility when $\mathcal{P}$	is a singleton. 
	
	\begin{example}
		Going back to Example~\ref{exm:DMU}, we have that 
		$$u(x_1)=p(A) - p(B) \textrm{ and } u(x_1)=p(B) - p(A)$$
		which means that the two acts will be incomparable according to maximality as soon as $\mathcal{P}$ contains a probability where $p(A)=p(B)$ that is not on the border of $\mathcal{P}$ (i.e., it contains at least one mass where $p(A)<p(B)$, and another where $p(B)>p(A)$). 
	\end{example}
	
	It should be noted that other authors have proposed different rules: for instance Levi~\cite{levi_enterprise_1983} recommends to use a decision rule, often called E-admissibility, that does not give rise to an incomplete order between acts, but rather selects all the acts that are Bayes optimal according to at least one probability $p \in \mathcal{P}$. In terms of order, this comes down to consider a set of possible linear ordering, and to retain only those elements that are maximal for at least one of them. 
	
	%Compared to maximality, E-admissibility implicitly uses the precise probabilities within the set $\mathcal{P}$, and therefore would not be consistent with Walley's view where the bounded (buying and selling) prices are not to be interpreted as incomplete information about an ideal precise price, but have to be considered as current state of knowledge that may not be reducible with additional information. 
	
	\subsubsection{Working with sets of probabilities and utilities}
	
	Sets of probabilities are helpful to represent incomplete beliefs or lack of information, yet it is natural to also consider cases where the \ac{DM} cannot provide a fully accurate estimation of utilities associated to consequences, or even to completely order them. In some sense, stochastic dominance is an extreme view of such a case, where consequences are ordered but the utility function is left totally unspecified. 
	
	Other works have dealt with partially specified utilities:
	\begin{itemize}
		\item \citet{dubra_expected_2004} represents preferences over lotteries by a set of utility functions. Preference holds whenever the expected utility for the preferred alternative is higher for all utility functions. This idea has been applied in other contexts \citep{ok_utility_2002}.
		\item \citet{dubra_model_2002} propose to view the preference relation as a completion of an intuitive partial preference relation: the \ac{DM} knows intuitively the result of some comparisons, and compute the other ones by applying some reasoning process. They also obtain a preference relation that is representable using a set of utility functions. This approach directly tackles some of the shortcomings described in \cref{sec:empirical}.
		\item \citet{manzini_representation_2008} use a utility function and a vagueness function, representing the preference using intervals of utilities rather than real valued utilities. %(Beyond DMU, also using this representation, \citet{masatlioglu_rational_2005} assume that a specific alternative called the status quo alternative is prominently chosen whenever the \ac{DM} faces a choice about which incomparability occur.)
	\end{itemize}

	There exist a few works where both requirements of precise probabilities and utilities are relaxed. This can be traced back at least to \citet{aumann_utility_1962} whose axioms do not require uniqueness of utilities: $x \succ y ⇒ u(x) > u(y)$, without requiring the reverse. More recently, \citet{galaabaatar_subjective_2013} are interested in the Savage-like context where probabilities are unknown and represent an incomplete preference relation in uncertaintly using a set of pairs of probabilities and utilities.


	\section{Incompleteness: absence of knowledge or knowledge of absence?}
	
	We have tried to browse a general picture of reasons why preference modelling should accommodate for incompleteness, and how it can do so in multi-criteria problems and uncertainty modelling. 
	
	One issue that transpired in most of the paper is whether incompleteness should be considered as an intrinsic, or ontic property of the preferences, in which case incomparability express a knowledge of absence of relation, or if incompleteness should be considered as an incomplete, epistemic description of a complete order, in which case it expresses an absence of knowledge. This mirrors different views about probability sets (Walley's consider that they model belief, without assuming an existing precise unknown distribution, while robust Bayesians consider the opposite). 
	
	Our opinion is that both views can be legitimate in different settings, and also that beyond the philosophical interest of distinguishing the two, this can have an important practical impact: knowing that incomparabilities are observable facts may influence strongly our information collection protocol; also, a same piece of information will be interpreted differently. If a \ac{DM} pick act $a$ among three acts $\{a,b,c\}$, in the espistemic interpretation, we woud deduce $a \succ \{b,c\}$, but in the ontic one we could only deduce that $a$ is a maximal element ($\neg(b\succ a)$ and $\neg(c\succ a)$)
%	
%	\section{Dropping transitivity}
%	
%	\subsection{Empirical evidences of intransitivity}
%	
%	\subsection{Under a normative view}
%	Fishburn is one of the prominent advocate about intransitivity holding even under normative approaches. Explain arguments…
%	
%	Roy has very much insisted on incomparability being taken into account explicitly in preference modeling. Explain…
%	
%	\subsection{Approaches that admit intransitivity in MCDM}
%	
%	\subsection{Approaches that admit intransitivity in MDU}
%	
%	* Statistical preferences, strongly related to the Condorcet paradox in social choice theory
%	
%	\subsection{Intransivity: a default to be repaired, or a fact to be modelled?}
	
\bibliography{Survey,seb}

\end{document}
