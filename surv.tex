\RequirePackage{amsmath}
%\RequirePackage[l2tabu, orthodox]{nag}
\documentclass[french, english]{llncs}
\input{preamble/packages}
\input{preamble/math_basics}
\input{preamble/math_mine}
\input{preamble/redac}
\input{preamble/draw}
\input{preamble/acronyms}

\begin{document}
	\title{Preference models that relax completeness or transitivity: why, how?}
	\author{Olivier Cailloux\inst{1} \and Sébastien Destercke\inst{2}}
	\institute{
		LAMSADE\\
		\email{olivier.cailloux@dauphine.fr}
		\and HDS
	}
	\hypersetup{
		pdfsubject={preference modeling},
		pdfkeywords={keyw1, keyw2}
	}
	\maketitle
	
	\abstract{Literature involving preferences of artificial agents or human beings often assume their preferences can be represented using a complete transitive binary relation. Much has been written however on more complex, or more interesting, models of preferences. In this article we review some of the reasons that have been put forward to justify more complex modeling, and review some of the techniques that have been proposed to obtain models of such preferences. (Optional: we connect to various related literature about argumentation, …)}
	
	%Oddly enough, llncs class seems to set the indent to zero when typesetting the abstract.
	\setlength{\parindent}{1.5em}
	
	\section{Introduction}\label{sec:intro}
	Preferences of agents are usually assumed to be linear, that is complete, transitive and antisymmetric, or representable with a weak order (a complete and transitive binary relation). In practice, such assumptions limit the scope of models (of uncertainty, of preferences) one can consider as legitimate, and are also falsified by observed empirical evidences. While models relaxing antisymmetry to allow incompleteness between options have been around for some time *** ELECTRE ?***, models relaxing the assumptions of completeness or transitivity are more recent.
	
	It is clear that our paper will not be complete, yet we think it gives a fair overview of why one would like to drop some of the above assumption. In particular, we will review both empirical evidence that preferences do not always follow the above assumption, thus relating them to more descriptive approaches, as well as formal  models that allows one to induce intransitive or incomplete preferences. 
	
	There are two canonical fields where the modelling of preferences is a central topic: choosing an alternative when it is evaluated according to different aspects (a.k.a. multi-criteria decision making, or MCDM), and picking an alternative whose quality depends on states of the world that are uncertainly known. Although the two frameworks are formally similar to some extent, they also present some key differences, if not formally then at least conceptually. 
	
	In MCDM, the common assumption is that the alternatives, i.e., the state of the world is known without ambiguity, and the difficulty is to determine what are the user preferences over these different, but well-defined states. In decision making under uncertainty (DMU), the preferences of the user are usually assumed to be well-known, or at least to have been previously assessed in the form of utility functions, and the problem is to recommend an alternative given our uncertainty about the world. 
	
	We will adopt the following basic scheme for the two settings (MCDM and DMU), that we will question later on, but that are necessary to set some notations.
	
	In MCDM, the classical approach is to assume that the alternatives are evaluated using a set of criteria $\crits$, each having an evaluation scale $X_g$. The set of all possible alternatives is $\allalts = \prod_{g \in G} X_g$, that is, every combination of evaluations are considered possible. Typical approaches assume that there is some real-valued function $v: \allalts \to \R$ mapping alternatives to their values, and that $x \succeq y$ iff  $v(x) ≥ v(y)$.
	
	\begin{example}
		Say the \ac{DM} must choose what to plant in her garden. The set of alternatives $\allalts$ are all possible vegetables, the criteria $\crits = \{g_1, g_2, g_3\}$ measure the taste, quantity, and price of each vegetable, and $\alts \subseteq \allalts$ are the vegetables that are available this year for planting. $X_{g_1} = \{A, B, C, D\}$, a set of labels, with $x_1$ representing the taste of the vegetable $x \in \allalts$ as considered by the \ac{DM} ($A$ is the worst taste, $D$ the best) \commentSD{Je me permets de changer, c'est plus facile pour mes exemples}, $X_{g_2} = [0, 100]$, with $x_2$ representing the number of meals that the \ac{DM} would enjoy if deciding to plant $x$, and $X_{g_3} = \R$, where $x_3$ indicates the price to pay for planting $x$.
	\end{example}
	
	In the simplest form of DMU considered here (SDMR, for Simple Decision Making under Risk), we consider a finite space $S$ of possible states of the world, a set of consequences $C$, and each act $x: S \to C$ is modelled as a function where $x(s)$ is the consequence of performing $x$ when $s$ is the actual state of the world. Define $\allalts$ in this case as the set of possible acts (thus $\allalts = C^S$). %Given $c \in C$, let $x_c$ denote the act that constantly yields $c$, thus, $x_c(s) = c, \forall s \in S$. 
	\commentSD{Pas certain qu'on ait besoin de l'acte constant, sauf si tu veux parler assez techniquement d'élicitation? En fait je suis assez peu familier de la littérature qui part des conséquences et des idées de lotteries, qui sont plutôt fu vNM, non?}
	In SDMR, uncertainty is modelled by a probability measure $p$ over the power set of $S$, $\powerset{S}$, thus with $p(s) \in [0, 1]$ indicating the probability of occurence of $s$, and $\sum_{s \in S} p(s) = 1$. Finally, it is often assumed that consequences can be mapped to a real-valued reward or utility through a function $a:C \to \R$, in which case we will simply denote by $a(s)$ the utility of performing $x$ in state $s$. The most common way to evaluate an $x$ is to use the notion of expected utility, which simply writes $u(x) = \sum_{s \in S} p(s) a(s)$.
	
	\begin{example}\label{exm:DMU}
		Assume a vegetable and its possible tastes ($S=\{A,B,C,D\}$). Given this vegetable, two actions are $x_1$: \``to eat it yourself" and $x_2$: \``give it to your neighbour", and the consequences are $c_1$: \``unhappy", $c_2$: \``neither happy nor unhappy" and $c_3$: \``happy". If the vegetable is very good ($x_1(A)=c_3,x_2(A)=c_1$), eating it will make you happy,  and giving it away will make you unhappy. On the contrary, if it is not very good ($x_1(D)=c_1,x_2(D)=c_3$) but edible, you will be happy to give a gift to your neighbour, but unhappy to eat it yourself. In the other situation, you are quite indifferent to both actions. Assuming that $p(A)=0.2, p(D)=0.6$ (you think it has a bad taste), $p(B)=p(C)=0.1$, and that $a(c_i)=i-2$, we then have
		$$u(x_1)=0.2 \cdot 1 + 0.6 \cdot -1 <  u(x_2)=0.2 \cdot -1 + 0.6 \cdot 1$$
	\end{example}
	
	All models presented thus far assume that it is possible to order alternatives according to their value, as given by a real function. Thus, they require $\succeq$ to be complete and transitive (by which we mean that if $\succeq$ is incomplete or not transitive, then no suitable function exists).
	
	The two contexts we have introduced, multiple criteria and risk, use as a basis the notion of a preference relation. We need to say a word about what those preferences really represent and what the goal of modeling those may be. This is required to give meaning to discussion about which conditions are reasonable to postulate about $\succeq$, and how to check whether they hold.
	
	\section{Different approaches to preference modeling}
	\subsection{Descriptive approach}
	In the descriptive approach to preferences, the goal of the model is to reflect the normal behavior of a \ac{DM}. Typically, we would have collected a database of sample choices of the \ac{DM}, say, of choices of food products in his favorite store, and we would try to obtain the model that best reflects his choice attitude. Or, we would query an individual’s preference about pairs of objects, and we would try to build a predictive relation on the whole set of possible pairs of alternatives. (Nowadays this would be called an “active learning” approach, but this term would be anachronic as the literature about this in decision theory pre-dates the field of machine learning.) Such a model may be used to predict his behavior, e.g. for marketing or regulation purposes. It may also be applied with the aim of replacing the \ac{DM} by automating his decision procedure, although it is debatable whether the normative approach would better suit this use case.
	
	Here is what von Neumann and Morgenstern say about the preference relation.
	
	“It is clear that every measurement --- or rather every claim of measurability --- must ultimately be based on some immediate sensation, which possibly cannot and certainly need not be analyzed any futher.
	[Such as the sensations of light, heat, muscular effort, etc., in the corresponding branches of physics.] 
	In the case of utility the immediate sensation of preference --- of one object or aggregate of objects as against another --- provides this basis.” (3.1.2) (The square brackets indicate a footnote.)
	
	“Let us for the moment accept the picture of an individual whose system of preferences is all-embracing and complete, i.e. who, for any two objects or rather for any two imagined events, possesses a clear intuition of preference. More precisely we expect him, for any two alternative events which are put before him as possibilities, to be able to tell which of the two he prefers.” (3.3.2) (The “events” here correspond to what we call alternatives.)
	
	As the preference relation is considered basic under a purely descriptive approach, the preference itself should be easily observable, and uncontroversial. This permits to test conditions postulated on $\succeq$. Either by asking the individual what she prefers (in which case we “observe” her answer), or by presenting a choice set and observing what she picks from that set (in real life or in a laboratory experiment). In the first case, we have however to be clear about what is meant by “prefers”, which is a reason why many experimenters prefer to go for the latter strategy.
	
	\subsection{Normative approach}
	Under the normative approach, the goal is to reflect on how the \ac{DM} ought to choose. Either according to external norms that are somehow (collectively) considered as representing rational behavior, or using some norms that the \ac{DM} himself accepts after careful reflexion. Hence, the decision outcome using such approach may differ from that the \ac{DM} would have chosen in his daily life. Consider as an example a responsible person in an enterprise who wants to model the procedure used to recruit employees. After having collected the figures, it may appear that, for some (possibly unconscious) reason, the recrutement is biased against some particular socio-economic or gender category, even considering equal competences. It may be, further, that the \ac{DM} himself is not happy about this situation. Thus, he may try to find a strategy of selecting employees that would avoid such biases, therefore actively trying \emph{not} to build a perfectly descriptive model of the normal selection attitude.
	
	When the focus is on providing decision help to a \ac{DM} by letting him think about and adopt the norms he prefers, rather than considering them as external norms that he ought to follow under threat of being considered irrational, the approach is often termed prescriptive, or constructive. There are important differences between these terms, and different authors use them somewhat differently. (Give refs.) The focus here being not on those differences, we refer to … and will use the general normative term as an umbrella.
	
	When building recommender systems in the literature in artificial intelligence, the focus is often on descriptive approaches. This is usually left implicit, with no discussion about possible alternatives. We think however that an interesting path is offered by normative approaches. Descriptive approaches will, by design, reflect cognitive limitations exhibited by us, normal human beings. Those limitations are numerous and sometimes obviously not in agreement with what a more thoughtful and knowledgeable person would do, as is well known and will be illustrated in this article (although there is debate about how such a sentence is to be interpreted exactly, more about this later). Providing (more) normative-based automatic recommendations might help provide sound advices, help increase serendipity, and possibly reduce incitations to merchants to exploit imperfections on the human reasoning abilities by using marketing techniques that may lead to choices that the \ac{DM} himself would possibly reject when thinking more carefully.
	
	\section{Dropping completeness}
	\commentOC{Je me permets d’inverser les sections à propos de completeness et de transitivity, car je suis nettement plus inspiré sur la question de la complétude. Mais cette inversion est négociable et potentiellement temporaire, bien sûr.}
	
	\subsection{Empirical evidence of incompleteness}
	A precise definition of what the preference relation $\succeq$ represents is required for discussing conditions postulated about it. For “preference”, in its everyday usage, is very ambiguous. (\citet{frankfurt_freedom_1971} cites seven reasonable interpretations of the phrase “to want to”; this exercice transposes, \emph{mutatis mutandis}, to the concept of preference.)
	
	Expanding on the proposition of nVM, we define that the \ac{DM} \emph{prefers} $a$ to $b$ when he expresses an intuitive attraction towards $a$ when presented with $a$ and $b$, or an equal attraction towards $a$ and $b$; and this attraction is stable over time (at least within a short time span) and does not change with irrelevant changes in the context. The second part of our definition makes it applicable also in case the intuitive attraction felt by the \ac{DM} changes for no apparent reason, or depends on the context at the moment of presenting $a$ and $b$ to the \ac{DM}, for example whether it is currently raining. Here we are interested in the multicriteria and SDMR settings, thus we assume that $a, b$ are alternatives in $\allalts$ described by their evaluations on the criteria (in the first case) or by the relevant probability distributions and consequences (in the second case), and consider irrelevant changes in the context as anything that does not change those descriptions. 
	This is by no means the only reasonable definition of a preference relation. We discuss alternative definitions of the preference relation later.
	
	Under this definition, postulating completeness of $\succeq$ amounts to state that the intuitive attractions of the \ac{DM} towards alternatives do not vary within short time spans and do not depend on irrelevant changes in the context. We think this is one reasonable way of capturing the essence of completeness, and it makes the condition empirically testable.
	
	It appears that this completeness assumption is too strong, for lack of stability over time for some pairs of alternatives. This is well known in the field of experimental psychology, and is not even presented as a remarkable fact. As Tversky (1969) writes, individuals “are not perfectly consistent in their choices. When faced with repeated choices between x and y, people often choose x in some instances and y in others. Furthermore, such inconsistencies are observed even in the absence of systematic changes in the decision maker’s taste which might be due to learning or sequential effects. It seems, therefore, that the observed inconsistencies reflect inherent variability or momentary fluctuation in the evaluative process.” 
	
	\citet[p. 630]{vNM} themselves considered completeness as a strong condition, as the following often cited quote indicates: “it is very dubious, whether the idealization of reality which treats this postulate as a valid one, is appropriate or even convenient”.
	The question thus may be considered to be not whether in reality preferences are complete, but rather whether a model of complete preferences may provide a useful approximation of it. Let us examine, to discuss this hypothesis, a second reason for failure of completeness.
	
	In order to discuss this hypothesis, we turn to the second (and much more interesting) reason for failure of completeness, which is also given by the literature in empirical psychology. It appears that preferences change in systematic ways according to changes in the presentation of the alternatives or the context that should have no impact from a normative point of view.
	
	\commentOC{Ici je n’ai pas encore décrit les expériences en détail, juste l’idée pour que tu voies où je veux en venir. Faudra voir de combien de place on dispose pour cet aspect. J’ai l’impression d’en avoir déjà fait des tonnes sur cette section.}
	
	Describe study MacCrimmon, Stanbury, and Wehrung (1980, Real money lotteries: A study of ideal risk, context effects, and simple processes. In T S. Wallsten (Ed.). Cognitive Process in Choice and Decision Behavior).
	
	When working under utility theory, it is common to ask questions about probability equivalent loteries, or about certainty equivalents. Systematic differences appear in the preferences exhibited between each mode of questioning. (Better description needed here.) 
	
	In situations of risk, a famous study \citep{tversky_1981} showed an important effect of framing. The subjects, split in two groups, have to choose a preferred program to prepare against an epidemic outspring which will, if no action is taken, result in the death of 600 persons. The first group must choose between program A, which saves 200 persons, and program B, which saves 600 persons with 1 chance on 3, and otherwise saves nobody. Most persons in that group choose program A. The second group must choose between program A', which lets 400 persons die, and B', which results in nobody dying with 1 chance on 3, and otherwise the death of 600 persons. Most persons in the second group choose program B'. Observe that both choices are identical up to phrasing. This illustrates an effect well-known in psychology, according to which choices phrased as losses are evaluated differently than choices phrased as gains.
	
	In multicriteria contexts, when the decision involves trade-offs, psychologists have shown systematic differences between choice and matching elicitation procedures \citep{tversky_contingent_1988}. Assume you want to know which of two alternatives $a, b$ the \ac{DM} prefers, in a problem involving two criteria. You can present both and directly ask for a choice. Alternatively, the matching procedure consists in presenting alternative $a$ with its two evaluations $g_1(a), g_2(a)$, and present alternative $b$ with only one evaluation $g_1(b)$, and ask the \ac{DM} to state the value $g'_2(b)$ which would make $b$ indifferent to $a$. Assuming $\succeq$ satisfies dominance and transitivity, you then know that $a \succeq b$ iff $g'_2(b) ≥ g_2(b)$.
	
	Other discussions and presentations of descriptive studies in the multicriteria and risk case are presented in \citet[Ch. 2]{deparis_2012}, \citet{slovic_construction_2006, Camerer and Ho (1994)}, …
	
	Physchologists talk about preference reversal effects when referring to situations where an individual ends up stating, indirectly, that he prefers $a$ to $b$ or $b$ to $a$ depending on the way the question is asked (possibly while assuming transitivity and dominance, as illustrated previously). Many advocate to view such effects as illustrating that preferences are constructed (by the process of elicitation), rather than given.
	
	This shows that the $\succeq$ relation as defined above is in general not complete. One way wish however to model a preference relation as complete anyway, in order, for example, to benefit from increased simplicity, tractability, or mathematical elegance of such models. One path for doing this is to consider the context as fixed, for example, consider the way of presenting the alternatives to the \ac{DM} as fixed. Thus, for example, the model would represent the preference as stated by the \ac{DM} when asked questions in terms of binary choices, and not when he is interrogated in terms of matching. Furthermore, the model would represent not a preference understood as the expression of clear intuitive attraction from the \ac{DM} towards some alternative, but rather as the a noisy intuitive attraction, known only imperfectly by the \ac{DM}. 
	
	In some cases, this is a perfectly reasonable path to follow. (This strategy is commonly followed in experimental psychology, for example, \citet{Luce} indicates that his book is about studying preferences in terms of choice and not of judgment; \citet{MacCrimmon} indicates that some kind of loteries should not be considered to belong to the scope of the model.) We of course do not claim that models of preference relations that assume completeness have no validity whatsoever, as the validity of a model depends on its purposes. In the case however not of psychologists but of researchers building recommender systems, it is unclear that this path should be systematically followed. Indeed, in some cases we may want the recommendations of the recommender system to be invariant to the particular details about how alternatives have been presented to the individual. Not only because we may not know how the alternatives have been presented (what the context is), but more fundamentally, because the individual may find the advices of a recommender system more sound if it is independent of minute details of the context. (Adopting this view of course makes the system closer to the normative approach.)
	
	Let us come back to the topic of completeness. These effects of framing are of course not everywhere \citep{slovic}. You can’t make someone choose whatever you want just by presenting it in the right way. (Or, at least, and luckily, we do not yet know how to do that.) Thus, another way of viewing the experimental highlights discussed here above is that a more meaningful model may be built on some subset of pairs that exhibit a stable preference. By forcing completeness in the model, we may build models that are partly irrelevant to the perception of the \ac{DM} we try to help: for some pairs of alternatives, there may be no sensible way, even conceptually, to determine whether some alternative is really preferred by the \ac{DM} to some other one.
	
	Talk here about lack of information leading to incomplete models even though the preference is intrisically complete?
	
	\subsection{Incompleteness in MCDM}
	
	* Robust MCDM a la Greco etc...
	
	* MCDM model that induce incomplete orders (CP-net... others?)
	
	\subsection{Incompleteness in DMU}
	
	\subsubsection{Justifying completeness in DMU}
	
	As recalled in Section~\ref{sec:intro}, probability theory and expected utility are the most widely used tools when having to decide under uncertainty. It has been justified axiomatically by different authors, the main ones being Savage (ref), De Finetti and Von Neumann Morgenstern. It is worth noticing the following things about these settings:
	\begin{itemize}
		\item In Savage and De Finetti settings, utilities or rewards of actions are supposed to be known, but the axioms assume, from the start, that any two actions can be compared by the decision maker (i.e., that the preference relation is complete). These axioms, along with some others, results in the use of probabilities and of expected utility as a unique rule. 
		\item In Von Neumann and Morgenstern, \commentSD{Olivier, là tu connais mieux que moi.} the axioms also assume completeness of the preferences and lead to expected utility as the unique valid rule, but here the probabilities are assumed to be known.
	\end{itemize}
	While these theoretical constructs have set very strong foundations for the use of probabilities, in practice experiments such as the Ellsberg urn suggest that people do not always act according to expected utility computed from a unique probability. And even before, researchers such as Keynes or Boole suggested that getting precise probabilities in practice was not a very realistic assumption. 
	
	Since then, many different extensions have been proposed, some modifying the utilities (ref to prospect theory) or the probabilities (ref to rank dependent utility). Others simply propose to relax the probabilistic assumption, for instance by considering a possibilistic setting where rewards can be non-numerical (ref to Dubois/Fargier), by considering sets of probabilities such as in the literature concerning decision under ambiguity (ref to Jean-marc Tallon and co), or by simply considering completely missing information, such as Wald (citation)  and his celebrated maximin criterion (widely used in decision under risk and in robust optimisation). Some other works also consider dropping the precision of utility functions (Gul/pesendorfer). However, not knowing the utility function is somehow similar to problems treated in MCDM, as the utility function does not express our lack of information about the state of the world, but our preferences about different options. 
	
	However, while these extensions do address some of the observed behaviours that do not comply with expected utility, their axiomatic or models keep assuming that every acts can or should be comparable between each others, hence that preferences should be complete. Yet, if one considers that probabilities or utilities may be incompletely known, the next natural step is to consider that preferences derived from them could also be incomplete. 
	
	\subsubsection{Keeping precise probabilities but not expected utility}
	
	Even when having precise probabilities, there are alternatives to expected utility that induce incomplete preferences. One of them that is particularly interesting is the notion of stochastic dominance. Assuming that your probability is defined over a completely ordered space $Y=\{y_1,\ldots,y_n\}$ (which can be your space of consequences), then an act modelled by probability $p_1$ is said to stochastically dominate another act modelled by probability $p_2$ iff for all $y_i$, we have
	\begin{equation}\label{eq:stodom}P_1(\{y_1,\ldots,y_i\})=\sum_{j=1}^i p_1(y_j) \leq P_2(\{y_1,\ldots,y_i\})=\sum_{j=1}^i p_2(y_j).\end{equation}
	Since Inequality~\eqref{eq:stodom} can be satisfied for some $y_i$ and not for others, possible incomparabilities immediately follow. It should be noticed that the probabilities $p_1,p_2$ may concern the same uncertain quantity, but may result from the mapping of the original probability $p$ to the space of (ordered) consequences, such as in \cref{exm:DMU}.
	
	Moreover, stochastic dominance may also be perceived as a criterion allowing for utilities to be ill-defined, as when $p_1$ stochastically dominates $p_2$, then its expected value for any increasing utility function $u$ defined over $Y$ (that is, $u(y_i) \leq u(y_{i+1})$) will be higher than the expected value of this utility function according to $p_2$. 
		
	\subsubsection{Incompleteness from non-precise probabilities}
	
	In the past few decades, different scholars have challenged what is sometimes called the \``dogma of precision" (Walley) of probabilities, advocating general theories based on sets of probabilities as a model rather than enforcing the need of a single probability. Such theories consider in general convex sets of probabilities, and recommend decision rules that extend expected utility but do allow, at least for some of them, incomparabilities to happen. 
	
	In such theories, our knowledge is no longer modelled by a single distribution $p$, but by a convex set $\mathcal{P}$ of them. 
	
	\begin{itemize}
		\item introduce expectation bounds
		\item introduce maximality
		\item speak about E-admissibility? not strictly speaking an ordering rule, but does have some interesting connection with the ontic/epistemic duality
		\item mention that every probabilistic decision rule can be extended to accomodate imprecision. 
	\end{itemize}
	
    
	
	\subsection{Incompleteness: absence of knowledge or knowledge of absence?}
	
	\section{Dropping transitivity}
	
	\subsection{Empirical evidences of intransitivity}
	
	\subsection{Under a normative view}
	Fishburn is one of the prominent advocate about intransitivity holding even under normative approaches. Explain arguments…
	
	Roy has very much insisted on incomparability being taken into account explicitly in preference modeling. Explain…
	
	\subsection{Approaches that admit intransitivity in MCDM}
	
	\subsection{Approaches that admit intransitivity in MDU}
	
	* Statistical preferences, strongly related to the Condorcet paradox in social choice theory
	
	\subsection{Intransivity: a default to be repaired, or a fact to be modelled?}
	
\end{document}
